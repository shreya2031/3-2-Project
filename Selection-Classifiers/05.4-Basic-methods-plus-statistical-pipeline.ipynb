{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Methods - Basics - Plus - Filter statistical tests\n",
    "\n",
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold, f_classif, SelectKBest\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, r2_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 36)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the Santander customer satisfaction dataset from Kaggle\n",
    "\n",
    "data = pd.read_csv('C:/Users/RAJENDRA REDDY/Downloads/Genre1.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft_min</th>\n",
       "      <th>chroma_stft_max</th>\n",
       "      <th>chroma_cqt_min</th>\n",
       "      <th>chroma_cqt_max</th>\n",
       "      <th>chroma_cens_min</th>\n",
       "      <th>chroma_cens_max</th>\n",
       "      <th>melspectogram_min</th>\n",
       "      <th>melspectogram_max</th>\n",
       "      <th>mfcc_min</th>\n",
       "      <th>mfcc_max</th>\n",
       "      <th>...</th>\n",
       "      <th>zero_crossing_rate_min</th>\n",
       "      <th>zero_crossing_rate_max</th>\n",
       "      <th>tempogram_min</th>\n",
       "      <th>tempogram_max</th>\n",
       "      <th>delta_mfcc_min</th>\n",
       "      <th>delta_mfcc_max</th>\n",
       "      <th>mel_to_stft_min</th>\n",
       "      <th>mel_to_stft_max</th>\n",
       "      <th>class</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001296</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.739581</td>\n",
       "      <td>8.890000e-06</td>\n",
       "      <td>6547.40700</td>\n",
       "      <td>-162.60739</td>\n",
       "      <td>148.07231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>0.305176</td>\n",
       "      <td>-2.850000e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>-27.087835</td>\n",
       "      <td>25.198893</td>\n",
       "      <td>0</td>\n",
       "      <td>18.772789</td>\n",
       "      <td>1</td>\n",
       "      <td>Aa To Sahii (sahi)_shortened.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002739</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020606</td>\n",
       "      <td>0.682328</td>\n",
       "      <td>1.990000e-09</td>\n",
       "      <td>3179.20950</td>\n",
       "      <td>-243.84023</td>\n",
       "      <td>156.03381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.543457</td>\n",
       "      <td>-2.850000e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>-24.831850</td>\n",
       "      <td>26.813145</td>\n",
       "      <td>0</td>\n",
       "      <td>14.955276</td>\n",
       "      <td>1</td>\n",
       "      <td>Aadat (23)_shortened.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003432</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025010</td>\n",
       "      <td>0.674345</td>\n",
       "      <td>1.470000e-06</td>\n",
       "      <td>367.87683</td>\n",
       "      <td>-197.41306</td>\n",
       "      <td>134.92323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.480957</td>\n",
       "      <td>-3.320000e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.765142</td>\n",
       "      <td>14.908866</td>\n",
       "      <td>0</td>\n",
       "      <td>9.169767</td>\n",
       "      <td>1</td>\n",
       "      <td>Aag Chahat Ki Lag Jayegi (1)_shortened.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000696</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049335</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777123</td>\n",
       "      <td>8.430000e-07</td>\n",
       "      <td>5928.97400</td>\n",
       "      <td>-204.65260</td>\n",
       "      <td>162.19836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.195801</td>\n",
       "      <td>-2.440000e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>-29.716740</td>\n",
       "      <td>21.724106</td>\n",
       "      <td>0</td>\n",
       "      <td>17.889960</td>\n",
       "      <td>1</td>\n",
       "      <td>Aahista Aahista (16)_shortened.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000197</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026210</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.782509</td>\n",
       "      <td>2.600000e-11</td>\n",
       "      <td>722.85565</td>\n",
       "      <td>-351.27094</td>\n",
       "      <td>223.67530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>0.239258</td>\n",
       "      <td>-3.610000e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>-22.297218</td>\n",
       "      <td>16.177706</td>\n",
       "      <td>0</td>\n",
       "      <td>10.572831</td>\n",
       "      <td>1</td>\n",
       "      <td>Aaiye Meharban (23)_shortened.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chroma_stft_min  chroma_stft_max  chroma_cqt_min  chroma_cqt_max  \\\n",
       "0         0.001296                1        0.033154               1   \n",
       "1         0.002739                1        0.062056               1   \n",
       "2         0.003432                1        0.056286               1   \n",
       "3         0.000696                1        0.049335               1   \n",
       "4         0.000197                1        0.026210               1   \n",
       "\n",
       "   chroma_cens_min  chroma_cens_max  melspectogram_min  melspectogram_max  \\\n",
       "0         0.003514         0.739581       8.890000e-06         6547.40700   \n",
       "1         0.020606         0.682328       1.990000e-09         3179.20950   \n",
       "2         0.025010         0.674345       1.470000e-06          367.87683   \n",
       "3         0.000000         0.777123       8.430000e-07         5928.97400   \n",
       "4         0.000000         0.782509       2.600000e-11          722.85565   \n",
       "\n",
       "    mfcc_min   mfcc_max  ...  zero_crossing_rate_min  zero_crossing_rate_max  \\\n",
       "0 -162.60739  148.07231  ...                0.020020                0.305176   \n",
       "1 -243.84023  156.03381  ...                0.008301                0.543457   \n",
       "2 -197.41306  134.92323  ...                0.054688                0.480957   \n",
       "3 -204.65260  162.19836  ...                0.004883                0.195801   \n",
       "4 -351.27094  223.67530  ...                0.024902                0.239258   \n",
       "\n",
       "   tempogram_min  tempogram_max  delta_mfcc_min  delta_mfcc_max  \\\n",
       "0  -2.850000e-16              1      -27.087835       25.198893   \n",
       "1  -2.850000e-16              1      -24.831850       26.813145   \n",
       "2  -3.320000e-16              1      -14.765142       14.908866   \n",
       "3  -2.440000e-16              1      -29.716740       21.724106   \n",
       "4  -3.610000e-16              1      -22.297218       16.177706   \n",
       "\n",
       "   mel_to_stft_min  mel_to_stft_max  class  \\\n",
       "0                0        18.772789      1   \n",
       "1                0        14.955276      1   \n",
       "2                0         9.169767      1   \n",
       "3                0        17.889960      1   \n",
       "4                0        10.572831      1   \n",
       "\n",
       "                                         song  \n",
       "0            Aa To Sahii (sahi)_shortened.wav  \n",
       "1                    Aadat (23)_shortened.wav  \n",
       "2  Aag Chahat Ki Lag Jayegi (1)_shortened.wav  \n",
       "3          Aahista Aahista (16)_shortened.wav  \n",
       "4           Aaiye Meharban (23)_shortened.wav  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 34), (60, 34))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['class','song'], axis=1),\n",
    "    data['class'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I keep a copy of the dataset with all the variables\n",
    "# to compare the performance of machine learning models\n",
    "# at the end of the notebook\n",
    "\n",
    "X_train_original = X_train.copy()\n",
    "X_test_original = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 30), (60, 30))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_features = [\n",
    "    feat for feat in X_train.columns if X_train[feat].std() == 0\n",
    "]\n",
    "\n",
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove quasi-constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "sel.fit(X_train) # finds the features with low variance\n",
    "\n",
    "sum(sel.get_support()) # how many not quasi-constant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = X_train.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 21), (60, 21))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the features\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn transformations lead to numpy arrays\n",
    "# here I transform the arrays back to dataframes\n",
    "\n",
    "X_train= pd.DataFrame(X_train)\n",
    "X_train.columns = features_to_keep\n",
    "\n",
    "X_test= pd.DataFrame(X_test)\n",
    "X_test.columns = features_to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicated features in the training set\n",
    "\n",
    "duplicated_feat = []\n",
    "for i in range(0, len(X_train.columns)):\n",
    "    if i % 10 == 0:  # this helps me understand how the loop is going\n",
    "        print(i)\n",
    "\n",
    "    col_1 = X_train.columns[i]\n",
    "\n",
    "    for col_2 in X_train.columns[i + 1:]:\n",
    "        if X_train[col_1].equals(X_train[col_2]):\n",
    "            duplicated_feat.append(col_2)\n",
    "            \n",
    "len(duplicated_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 21), (60, 21))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicated features\n",
    "X_train.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I keep a copy of the dataset except constant and duplicated variables\n",
    "# to measure the performance of machine learning models\n",
    "# at the end of the notebook\n",
    "\n",
    "X_train_basic_filter = X_train.copy()\n",
    "X_test_basic_filter = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated features:  10\n"
     ]
    }
   ],
   "source": [
    "# find and remove correlated features\n",
    "def correlation(dataset, threshold):\n",
    "    \n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            # we are interested in absolute coeff value\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    \n",
    "    return col_corr\n",
    "\n",
    "\n",
    "corr_features = correlation(X_train, 0.8)\n",
    "print('correlated features: ', len(set(corr_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 11), (60, 11))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove correlated features\n",
    "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a copy of the dataset at  this stage\n",
    "X_train_corr = X_train.copy()\n",
    "X_test_corr = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features based of anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rajendra reddy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "  msb = ssbn / float(dfbn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['mfcc_min', 'mfcc_max', 'spectral_centroid_min',\n",
       "       'spectral_centroid_max', 'spectral_contrast_min',\n",
       "       'spectral_contrast_max', 'tonnetz_min', 'tonnetz_max', 'delta_mfcc_min',\n",
       "       'delta_mfcc_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_ = SelectKBest(f_classif, k=10).fit(X_train, y_train)\n",
    "\n",
    "# capture selected feature names\n",
    "features_to_keep = X_train.columns[sel_.get_support()]\n",
    "\n",
    "# select features\n",
    "X_train_anova = sel_.transform(X_train)\n",
    "X_test_anova = sel_.transform(X_test)\n",
    "\n",
    "# numpy array to dataframe\n",
    "X_train_anova = pd.DataFrame(X_train_anova)\n",
    "X_train_anova.columns = features_to_keep\n",
    "\n",
    "X_test_anova = pd.DataFrame(X_test_anova)\n",
    "X_test_anova.columns = features_to_keep\n",
    "\n",
    "X_train_anova.shape, X_test_anova.shape\n",
    "features_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy, testy = y_train, y_test\n",
    "# define outlier detection model\n",
    "trainX = X_train[features_to_keep]\n",
    "testX =  X_test[features_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.986\n",
      "F1 Score: 0.993\n",
      "Precision Score: 0.986\n",
      "Recall Score: 0.986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "# generate dataset\n",
    "\n",
    "# split into train/test sets\n",
    "\n",
    "model = OneClassSVM(gamma='scale', nu=0.01)\n",
    "# fit on majority class\n",
    "\n",
    "model.fit(trainX)\n",
    "# detect outliers in the test set\n",
    "yhat = model.predict(trainX)\n",
    "# mark inliers 1, outliers -1\n",
    "\n",
    "# calculate score\n",
    "\n",
    "print('Accuracy Score: %.3f' % accuracy_score(y_train, yhat))\n",
    "print('F1 Score: %.3f' % f1_score(y_train, yhat, pos_label=1))\n",
    "print('Precision Score: %.3f' % precision_score(y_train, yhat, average='micro'))\n",
    "print('Recall Score: %.3f' % recall_score(y_train, yhat, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.986\n",
      "F1 Score: 0.993\n",
      "Precision Score: 0.986\n",
      "Recall Score: 0.986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "# generate dataset\n",
    "\n",
    "# define outlier detection model\n",
    "model = EllipticEnvelope(contamination=0.01)\n",
    "# fit on majority class\n",
    "\n",
    "model.fit(trainX)\n",
    "# detect outliers in the test set\n",
    "yhat = model.predict(trainX)\n",
    "# mark inliers 1, outliers -1\n",
    "\n",
    "# calculate score\n",
    "print('Accuracy Score: %.3f' % accuracy_score(y_train, yhat))\n",
    "print('F1 Score: %.3f' % f1_score(y_train, yhat, pos_label=1))\n",
    "print('Precision Score: %.3f' % precision_score(y_train, yhat, average='micro'))\n",
    "print('Recall Score: %.3f' % recall_score(y_train, yhat, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "# generate dataset\n",
    "\n",
    "# split into train/test sets\n",
    "\n",
    "# define outlier detection model\n",
    "model = IsolationForest(contamination=0.01)\n",
    "# fit on majority class\n",
    "\n",
    "model.fit(trainX)\n",
    "# detect outliers in the test set\n",
    "yhat = model.predict(trainX)\n",
    "# mark inliers 1, outliers -1\n",
    "\n",
    "# calculate score\n",
    "score = f1_score(trainy, yhat, pos_label=1)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.993\n"
     ]
    }
   ],
   "source": [
    "from numpy import vstack\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# make a prediction with a lof model\n",
    "def lof_predict(model, trainX, testX):\n",
    "\t# create one large dataset\n",
    "\tcomposite = vstack((trainX, testX))\n",
    "\t# make prediction on composite dataset\n",
    "\tyhat = model.fit_predict(composite)\n",
    "\t# return just the predictions on the test set\n",
    "\treturn yhat[len(trainX):]\n",
    "\n",
    "# generate dataset\n",
    "\n",
    "# split into train/test sets\n",
    "\n",
    "# define outlier detection model\n",
    "model = LocalOutlierFactor(contamination=0.01)\n",
    "# get examples for just the majority class\n",
    "\n",
    "# detect outliers in the test set\n",
    "yhat = lof_predict(model,testX,trainX)\n",
    "# mark inliers 1, outliers -1\n",
    "\n",
    "# calculate score\n",
    "score = f1_score(trainy, yhat, pos_label=1)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the performance in machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build random forests and\n",
    "# compare its performance in train and test sets\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred)))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-b4d3ca49490d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m run_randomForests(X_train_original,\n\u001b[0;32m      3\u001b[0m                   \u001b[0mX_test_original\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                   y_train, y_test)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-140-aea7bf69118f>\u001b[0m in \u001b[0;36mrun_randomForests\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Random Forests roc-auc: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rajendra reddy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rajendra reddy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    543\u001b[0m                                              max_fpr=max_fpr),\n\u001b[0;32m    544\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    546\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# multilabel-indicator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         return _average_binary_score(partial(_binary_roc_auc_score,\n",
      "\u001b[1;32mc:\\users\\rajendra reddy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rajendra reddy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;34m\"\"\"Binary roc auc score.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[0;32m    328\u001b[0m                          \"is not defined in that case.\")\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "# original\n",
    "run_randomForests(X_train_original,\n",
    "                  X_test_original,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-fd102fa0ab7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneClassSVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Ada Boost roc-auc: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "X_train = X_train[features_to_keep]\n",
    "X_test =  X_test[features_to_keep]\n",
    "from sklearn.svm import OneClassSVM\n",
    "clf = OneClassSVM(gamma='auto').fit(X_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Ada Boost roc-auc: {}'.format(score = f1_score(y_test, y_pred, pos_label=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.986\n",
      "F1 Score: 0.993\n",
      "Precision Score: 0.986\n",
      "Recall Score: 0.986\n"
     ]
    }
   ],
   "source": [
    "# one-class svm for imbalanced binary classification\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "# generate dataset\n",
    "\n",
    "# split into train/test sets\n",
    "trainy, testy = y_train, y_test\n",
    "# define outlier detection model\n",
    "trainX = X_train[features_to_keep]\n",
    "testX =  X_test[features_to_keep]\n",
    "model = OneClassSVM(gamma='scale', nu=0.01)\n",
    "# fit on majority class\n",
    "\n",
    "model.fit(trainX)\n",
    "# detect outliers in the test set\n",
    "yhat = model.predict(trainX)\n",
    "# mark inliers 1, outliers -1\n",
    "\n",
    "# calculate score\n",
    "\n",
    "print('Accuracy Score: %.3f' % accuracy_score(y_train, yhat))\n",
    "print('F1 Score: %.3f' % f1_score(y_train, yhat, pos_label=1))\n",
    "print('Precision Score: %.3f' % precision_score(y_train, yhat, average='micro'))\n",
    "print('Recall Score: %.3f' % recall_score(y_train, yhat, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-2ad414e60899>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m run_randomForests(X_train_basic_filter,\n\u001b[0;32m      3\u001b[0m                   \u001b[0mX_test_basic_filter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                   y_train, y_test)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-76-aea7bf69118f>\u001b[0m in \u001b[0;36mrun_randomForests\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Random Forests roc-auc: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rajendra reddy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rajendra reddy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    543\u001b[0m                                              max_fpr=max_fpr),\n\u001b[0;32m    544\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    546\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# multilabel-indicator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         return _average_binary_score(partial(_binary_roc_auc_score,\n",
      "\u001b[1;32mc:\\users\\rajendra reddy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rajendra reddy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;34m\"\"\"Binary roc auc score.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[0;32m    328\u001b[0m                          \"is not defined in that case.\")\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "# filter methods - basic\n",
    "run_randomForests(X_train_basic_filter,\n",
    "                  X_test_basic_filter,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8066004772684517\n",
      "Test set\n",
      "Random Forests roc-auc: 0.7859521124929707\n"
     ]
    }
   ],
   "source": [
    "# filter methods - correlation\n",
    "run_randomForests(X_train_corr,\n",
    "                  X_test_corr,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8181634778452822\n",
      "Test set\n",
      "Random Forests roc-auc: 0.7994720109870546\n"
     ]
    }
   ],
   "source": [
    "# filter methods - univariate roc-auc\n",
    "run_randomForests(X_train_anova,\n",
    "                  X_test_anova,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the 20 features we selected using the univariate anova are doing a good job, as the final model does not show a decrease in performance compared to that one using all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression\n",
    "# and compare its performance in train and test sets\n",
    "\n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(penalty='l1', random_state=44, max_iter=1000, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_train))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(scaler.transform(X_test))\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.7430426412785165\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.7514165331434336\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "run_logistic(X_train_original,\n",
    "             X_test_original,\n",
    "             y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.7410468829538979\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.7489081614486635\n"
     ]
    }
   ],
   "source": [
    "# filter methods - basic\n",
    "\n",
    "run_logistic(X_train_basic_filter,\n",
    "             X_test_basic_filter,\n",
    "             y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.7307283864065812\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.7227227435986561\n"
     ]
    }
   ],
   "source": [
    "# filter methods - correlation\n",
    "\n",
    "run_logistic(X_train_corr,\n",
    "             X_test_corr,\n",
    "             y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.7385311277520487\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.7256599156189685\n"
     ]
    }
   ],
   "source": [
    "# filter methods - univariate anova\n",
    "\n",
    "run_logistic(X_train_anova,\n",
    "             X_test_anova,\n",
    "             y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For logistic regression, we see that when we removed correlated features, we seemed to have removed some features that were good at predicting the target, as the performance dropped a bit.\n",
    "\n",
    "Why don't you try to apply the univariate anova without removing features by correlation, to see if the selected features are good enough?\n",
    "\n",
    "That is all for this lecture. I hope you enjoyed it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
